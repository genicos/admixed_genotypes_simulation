{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "212a7a5f-076d-46e6-af4e-8cff4a1ab2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Available memory: 64.25 GB\n",
      "_1000\n",
      "_2000\n",
      "_3000\n",
      "_4000\n",
      "_5000\n",
      "_6000\n",
      "_7000\n",
      "_8000\n",
      "_9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "torch.Size([91032, 11000])\n",
      "Available memory: 49.20 GB\n",
      "Available memory: 49.20 GB\n",
      "Total time elapsed: 0h 11m 12s\n"
     ]
    }
   ],
   "source": [
    "from processing import *\n",
    "from models import *\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ast import literal_eval\n",
    "import sys\n",
    "\n",
    "save_file = sys.argv[1] if sys.argv[1].endswith(\".pth\") else sys.argv[1] + \".pth\"\n",
    "data_dir = \"../Data7\"\n",
    "GPU_available = torch.cuda.is_available()\n",
    "print(GPU_available)\n",
    "num_files = 50_000\n",
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "train_prop = 0.9\n",
    "num_estimate = 5000\n",
    "lr_start = 3e-3\n",
    "lr_end = lr_start/100\n",
    "\n",
    "GetMemory()\n",
    "X = [convert_files(data_dir + \"/sampled_genotypes/sample_\" + str(i), data_dir + \"/commands/command_\" + str(i)) for i in range(num_files)] \n",
    "\n",
    "C = [convert_command_file1(data_dir + \"/commands/command_\" + str(i)) for i in range(num_files) if X[i] is not None]\n",
    "\n",
    "X = [x for x in X if x is not None]\n",
    "\n",
    "\n",
    "X = torch.tensor(X) - 1\n",
    "X = X.reshape(-1, sample_width*num_chrom * 2)\n",
    "\n",
    "print(X.shape)\n",
    "C = torch.tensor(C)\n",
    "C = C.reshape(-1, 13)\n",
    "\n",
    "GetMemory()\n",
    "\n",
    "y = torch.tensor([i%2 for i in range(1,X.shape[0] + 1)])\n",
    "\n",
    "# Scramble data\n",
    "torch.manual_seed(random_seed)\n",
    "ind = int(train_prop * X.shape[0]) // 4\n",
    "idx = torch.randperm(X.shape[0] // 4)\n",
    "idx = [4*i     for i in idx[:ind]] + [4*i + 1 for i in idx[:ind]] \\\n",
    "    + [4*i + 2 for i in idx[:ind]] + [4*i + 3 for i in idx[:ind]] \\\n",
    "    + [4*i     for i in idx[ind:]] + [4*i + 1 for i in idx[ind:]] \\\n",
    "    + [4*i + 2 for i in idx[ind:]] + [4*i + 3 for i in idx[ind:]] \n",
    "\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "C = C[idx]\n",
    "\n",
    "# Split data\n",
    "ind = int(train_prop * X.shape[0])\n",
    "X_train, X_test = X[:ind], X[ind:]\n",
    "y_train, y_test = y[:ind], y[ind:]\n",
    "C_train, C_test = C[:ind], C[ind:]\n",
    "\n",
    "GetMemory()\n",
    "GetTime()\n",
    "\n",
    "# lr variables\n",
    "lr = lr_start\n",
    "lr_factor = (lr_end/lr_start)**(1/(num_epochs - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47a1c404-8851-42dd-95cb-707dbc29c8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel1(\n",
       "  (pos_embedding): Embedding(110, 102)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (multihead): MultiHead(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x Head(\n",
       "            (key): Linear(in_features=102, out_features=32, bias=False)\n",
       "            (query): Linear(in_features=102, out_features=32, bias=False)\n",
       "            (value): Linear(in_features=102, out_features=32, bias=False)\n",
       "            (dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (linear): Linear(in_features=192, out_features=102, bias=True)\n",
       "        (dropout): Dropout(p=0.15, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=102, out_features=408, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=408, out_features=102, bias=True)\n",
       "          (3): Dropout(p=0.15, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((102,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((102,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (multihead): MultiHead(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x Head(\n",
       "            (key): Linear(in_features=102, out_features=32, bias=False)\n",
       "            (query): Linear(in_features=102, out_features=32, bias=False)\n",
       "            (value): Linear(in_features=102, out_features=32, bias=False)\n",
       "            (dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (linear): Linear(in_features=192, out_features=102, bias=True)\n",
       "        (dropout): Dropout(p=0.15, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=102, out_features=408, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=408, out_features=102, bias=True)\n",
       "          (3): Dropout(p=0.15, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((102,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((102,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (multihead): MultiHead(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x Head(\n",
       "            (key): Linear(in_features=102, out_features=32, bias=False)\n",
       "            (query): Linear(in_features=102, out_features=32, bias=False)\n",
       "            (value): Linear(in_features=102, out_features=32, bias=False)\n",
       "            (dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (linear): Linear(in_features=192, out_features=102, bias=True)\n",
       "        (dropout): Dropout(p=0.15, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=102, out_features=408, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=408, out_features=102, bias=True)\n",
       "          (3): Dropout(p=0.15, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((102,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((102,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (multihead): MultiHead(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x Head(\n",
       "            (key): Linear(in_features=102, out_features=32, bias=False)\n",
       "            (query): Linear(in_features=102, out_features=32, bias=False)\n",
       "            (value): Linear(in_features=102, out_features=32, bias=False)\n",
       "            (dropout): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (linear): Linear(in_features=192, out_features=102, bias=True)\n",
       "        (dropout): Dropout(p=0.15, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=102, out_features=408, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=408, out_features=102, bias=True)\n",
       "          (3): Dropout(p=0.15, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((102,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((102,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (multihead): MultiHead(\n",
       "    (heads): ModuleList(\n",
       "      (0-5): 6 x Head(\n",
       "        (key): Linear(in_features=102, out_features=32, bias=False)\n",
       "        (query): Linear(in_features=102, out_features=32, bias=False)\n",
       "        (value): Linear(in_features=102, out_features=32, bias=False)\n",
       "        (dropout): Dropout(p=0.15, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=192, out_features=102, bias=True)\n",
       "    (dropout): Dropout(p=0.15, inplace=False)\n",
       "  )\n",
       "  (linear1): Linear(in_features=11220, out_features=2805, bias=True)\n",
       "  (ln1): LayerNorm((11220,), eps=1e-05, elementwise_affine=True)\n",
       "  (ln2): LayerNorm((2805,), eps=1e-05, elementwise_affine=True)\n",
       "  (ln3): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "  (linear2): Linear(in_features=2805, out_features=100, bias=True)\n",
       "  (linear3): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (dropout): Dropout(p=0.15, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = TransformerModel1()\n",
    "model.load_state_dict(torch.load(\"time_le_300.pth\"))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4046fce9-c5f7-4dae-b86c-7593299af5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_full(split):\n",
    "    X, y, C = (X_train, y_train, C_train) if split == \"train\" else (X_test, y_test, C_test)\n",
    "    return X, y, C\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss_full():\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        X, y, C = get_batch_full(split)\n",
    "        y = y.to(device)\n",
    "        C = C.to(device)\n",
    "        y_pred = torch.zeros(X.shape[0])\n",
    "        for i in range(0, X.shape[0], batch_size):\n",
    "            try:\n",
    "                X_batch = X[i:i+batch_size].to(device)\n",
    "                y_pred[i:i+batch_size] = model(X_batch)\n",
    "            except IndexError:\n",
    "                X_batch = X[i:].to(device)\n",
    "                y_pred[i:] = model(X_batch)\n",
    "\n",
    "        if GPU_available:\n",
    "            y_pred = y_pred.to(\"cuda\")                       \n",
    "        \n",
    "        weak_epistasis = (C[:,7] < C[:,10])\n",
    "        weak_count = weak_epistasis.sum().item()\n",
    "        \n",
    "        predictions = (y_pred >= 0.5).int()\n",
    "\n",
    "\n",
    "        print()\n",
    "        print(split, \"full set:\")\n",
    "\n",
    "        num_correct = (predictions == y).sum().item()\n",
    "        acc = num_correct/X.shape[0]\n",
    "        print(f\" Accuracy {split}: {acc:0.4f}\")\n",
    "\n",
    "        print(\"\\t0\\t1\")\n",
    "        for i in range(2):\n",
    "            called_0 = torch.sum((predictions == 0) & (y == i)).item()\n",
    "            called_1 = torch.sum((predictions == 1) & (y == i)).item()\n",
    "            sums = called_0 + called_1\n",
    "            called_0 /= sums\n",
    "            called_1 /= sums\n",
    "            print(i, f\"{called_0:.3f}\" , f\"{called_1:.3f}\", sep='\\t')\n",
    "        \n",
    "\n",
    "            \n",
    "        called_epistasic = (predictions == 1)\n",
    "        \n",
    "        print()\n",
    "        print(split, \"M and T evaluation\")\n",
    "\n",
    "        for i in range(8):\n",
    "            minim = 0.1 + i/10\n",
    "            maxum = 0.2 + i/10\n",
    "\n",
    "            # admixture proportion\n",
    "            subset_0 = ((C[:,1] >= minim) & (C[:,1] < maxum))\n",
    "\n",
    "            for j in range(10):\n",
    "\n",
    "                minim = 100 + j*50\n",
    "                maxum = 150 + j*50\n",
    "\n",
    "                # admixture time\n",
    "                subset_1 = ((C[:,2] >= minim) & (C[:,2] < maxum))\n",
    "\n",
    "                subset = (subset_0 & subset_1 & called_epistasic)\n",
    "\n",
    "                #Counting proportion of those called epistasis which are correct\n",
    "\n",
    "                subset_count = subset.sum().item()\n",
    "                num_correct = ((predictions == y) & subset).sum().item()\n",
    "\n",
    "                if subset_count == 0:\n",
    "                    print(\"0\",end='')\n",
    "                    continue\n",
    "                \n",
    "                ratio = num_correct / subset_count\n",
    "\n",
    "                if ratio < 0.5:\n",
    "                    print(\".\",end='')\n",
    "                elif ratio < 0.66:\n",
    "                    print(\"-\",end='')\n",
    "                elif ratio < 0.80:\n",
    "                    print(\"+\",end='')\n",
    "                elif ratio < 0.95:\n",
    "                    print(\"$\",end='')\n",
    "                else:\n",
    "                    print(\"#\",end='')\n",
    "            \n",
    "            print()\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(split, \"epistrength 1 and 2 evaluation\")\n",
    "\n",
    "        for i in range(9):\n",
    "            minim = 0.01 + i * 0.01\n",
    "            maxum = 0.02 + i * 0.01\n",
    "\n",
    "            subset_0 = ((C[:,7] >= minim) & (C[:,7] < maxum))\n",
    "\n",
    "            for j in range(9):\n",
    "\n",
    "                minim = 0.01 + j * 0.01\n",
    "                maxum = 0.02 + j * 0.01\n",
    "\n",
    "                subset_1 = ((C[:,11] >= minim) & (C[:,11] < maxum))\n",
    "\n",
    "                subset = (subset_0 & subset_1 & called_epistasic)\n",
    "\n",
    "                subset_count = subset.sum().item()\n",
    "                num_correct = ((predictions == y) & subset).sum().item()\n",
    "\n",
    "                if subset_count == 0:\n",
    "                    print(\"0\",end='')\n",
    "                    continue\n",
    "                \n",
    "                ratio = num_correct / subset_count\n",
    "\n",
    "                if ratio < 0.5:\n",
    "                    print(\".\",end='')\n",
    "                elif ratio < 0.66:\n",
    "                    print(\"-\",end='')\n",
    "                elif ratio < 0.80:\n",
    "                    print(\"+\",end='')\n",
    "                elif ratio < 0.95:\n",
    "                    print(\"$\",end='')\n",
    "                else:\n",
    "                    print(\"#\",end='')\n",
    "            \n",
    "            print()\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2cedb4f-5990-4cd3-9ee0-d081719cd9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train full set:\n",
      " Accuracy train: 0.6554\n",
      "\t0\t1\n",
      "0\t0.747\t0.253\n",
      "1\t0.437\t0.563\n",
      "\n",
      "train M and T evaluation\n",
      "0000000000\n",
      "---++00000\n",
      "+++++00000\n",
      "-----00000\n",
      "----$00000\n",
      "$$$$#00000\n",
      "$$$$+00000\n",
      "0000000000\n",
      "\n",
      "train epistrength 1 and 2 evaluation\n",
      "+++$+++++\n",
      "+++$$++++\n",
      "++++++++-\n",
      "+++++-+--\n",
      "++++++---\n",
      "++++-----\n",
      "+++++----\n",
      "++++-----\n",
      "++++-----\n",
      "\n",
      "\n",
      "test full set:\n",
      " Accuracy test: 0.6596\n",
      "\t0\t1\n",
      "0\t0.737\t0.263\n",
      "1\t0.418\t0.582\n",
      "\n",
      "test M and T evaluation\n",
      "0000000000\n",
      "++--000000\n",
      "+++$#00000\n",
      "----000000\n",
      "----#00000\n",
      "$$$$#00000\n",
      "+++$#00000\n",
      "0000000000\n",
      "\n",
      "test epistrength 1 and 2 evaluation\n",
      "-++++++++\n",
      "++$$+++++\n",
      "+$++-+++-\n",
      "++++$+--+\n",
      "$+++++++-\n",
      "+++-+++--\n",
      "+$++--+--\n",
      "++++-----\n",
      "++++-----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6596001757469244"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_loss_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8de4f66-bbf8-499e-9359-cde806d8c340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977825e-c3af-48bd-9b7b-aee7ef62fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "if GPU_available:\n",
    "    print(\"GPU is available.\")\n",
    "    model = model.to(\"cuda\")\n",
    "    criterion = criterion.to(\"cuda\")\n",
    "#    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:<enter-size-here>\"\n",
    "else:\n",
    "    print(\"No GPU available. Running on CPU.\")\n",
    "\n",
    "GetMemory()\n",
    "# estimate_loss(min(num_estimate, X_test.shape[0]))\n",
    "#Training loop\n",
    "\n",
    "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb: SIZE\"\n",
    "\n",
    "best_acc = 0\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "    print(f\"Started training on epoch {epoch + 1} of {num_epochs}, learning rate {lr:0.7f}\")\n",
    "    GetTime()\n",
    "    # Scramble data\n",
    "    idx = torch.randperm(X_train.shape[0])\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "\n",
    "    # Shuffle in sampling dimension\n",
    "    X_train = X_train.reshape(-1,2*sample_width,num_chrom)\n",
    "    idx = torch.randperm(num_chrom)\n",
    "    X_train = X_train[:,:,idx]\n",
    "\n",
    "    # Randomly switch two sites \n",
    "    mask = torch.rand(X_train.shape[0]) < 0.5\n",
    "    shift_indices = torch.fmod(torch.arange(2*sample_width) + sample_width, 2*sample_width)\n",
    "    X_train[mask] = X_train[mask][:, shift_indices]\n",
    "\n",
    "\n",
    "    X_train = X_train.reshape(-1,sample_width*num_chrom*2)\n",
    "    # Randomly muliply each example by 1 or -1\n",
    "    # rand = torch.randint(0,2,size=(X_train.shape[0],1)) * 2 - 1\n",
    "    # X_train *= rand\n",
    "\n",
    "\n",
    "    for ind in range(0,X_train.shape[0],batch_size):\n",
    "\n",
    "        #print(torch.cuda.max_memory_allocated(),\"and\", torch.cuda.memory_allocated())\n",
    "\n",
    "        try:\n",
    "            X_batch = X_train[ind:ind+batch_size]\n",
    "            y_batch = y_train[ind:ind+batch_size]\n",
    "        except IndexError:\n",
    "            X_batch = X_train[ind:]\n",
    "            y_batch = y_train[ind:]\n",
    "\n",
    "        if GPU_available:\n",
    "            X_batch = X_batch.to(\"cuda\")\n",
    "            y_batch = y_batch.to(\"cuda\")\n",
    "\n",
    "        try:\n",
    "            y_pred = model(X_batch)\n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            torch.cuda.empty_cache()\n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "\n",
    "        loss = criterion(y_pred, y_batch.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    lr *= lr_factor\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "\n",
    "    acc = estimate_loss(min(num_estimate, X_test.shape[0]))\n",
    "    # for child in model.children():\n",
    "    #     if isinstance(child,nn.Linear):\n",
    "    #         print(\"next\")\n",
    "    #         print(\"weight\")\n",
    "    #         print(child.weight)\n",
    "    #         print(\"bias\")\n",
    "    #         print(child.bias)\n",
    "\n",
    "    if save_file.lower() != \"none.pth\" and acc > best_acc:\n",
    "        best_acc = acc\n",
    "        print(\"SAVING MODEL\")\n",
    "        torch.save(model.state_dict(), save_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
